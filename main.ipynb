{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ec1181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import pytesseract as pyt\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import DBSCAN\n",
    "pyt.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52be3e20",
   "metadata": {},
   "source": [
    "# Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d0fc2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoying_book = cv.imread(\"Testing/Book.png\")\n",
    "annoying_wreath = cv.imread(\"Testing/wreath.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e0314",
   "metadata": {},
   "source": [
    "# Display\n",
    "\n",
    "A function used for displaying images in-line rather than as a separate window. Input is a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e362bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function display copied shamelessly in its entirety\n",
    "def display(im_data):\n",
    "    dpi = 80\n",
    "\n",
    "    height, width  = im_data.shape[:2]\n",
    "    \n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def display_items(items: list):\n",
    "    for item in items:\n",
    "        display(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59518586",
   "metadata": {},
   "source": [
    "# Preprocessing - raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts image to binary\n",
    "\n",
    "img = cv.imread(\"Source data/2.png\")\n",
    "def to_bin(im):\n",
    "    if len(im.shape) == 3:\n",
    "        im = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "    _, im_bw = cv.threshold(im, 185, 255, cv.THRESH_BINARY)\n",
    "    return im_bw\n",
    "\n",
    "im_bw = to_bin(img)\n",
    "\n",
    "display(im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# some objects are messing up text recognition. the function below\n",
    "# removes them\n",
    "\n",
    "def remove_object(img, template, threshold=0.72, scales=np.linspace(0.5, 1.4, 30)):\n",
    "    bin = to_bin(img)\n",
    "\n",
    "    #checks a range of scales\n",
    "    for scale in scales:\n",
    "        # Resize the template\n",
    "        temp_resized = cv.resize(template, None, fx=scale, fy=scale, interpolation=cv.INTER_AREA)\n",
    "        temp_resized = to_bin(temp_resized)\n",
    "        th, tw = temp_resized.shape[:2]\n",
    "        if th > bin.shape[0] or tw > bin.shape[1]:\n",
    "            continue  # skip if resized template is bigger than image\n",
    "\n",
    "        # Template matching\n",
    "        res = cv.matchTemplate(bin, temp_resized, cv.TM_CCOEFF_NORMED)\n",
    "        loc = np.where(res >= threshold)\n",
    "\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            cv.rectangle(img, pt, (pt[0] + tw, pt[1] + th), (255,255,255), -1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087def76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divides image into three: first row contains years, second contains periods,\n",
    "# and third contains courses\n",
    "\n",
    "def split_image(img, template, threshold=0.74, scales=np.linspace(0.5, 1.4, 30)):\n",
    "    bin = to_bin(img)\n",
    "    all_detected = np.array([])\n",
    "    \n",
    "    for scale in scales:\n",
    "        # Resize the template\n",
    "        temp_resized = cv.resize(template, None, fx=scale, fy=scale, interpolation=cv.INTER_AREA)\n",
    "        temp_resized = to_bin(temp_resized)\n",
    "        th, tw = temp_resized.shape[:2]\n",
    "        if th > bin.shape[0] or tw > bin.shape[1]:\n",
    "            continue  # skip if resized template is bigger than image\n",
    "\n",
    "        # Template matching\n",
    "        res = cv.matchTemplate(bin, temp_resized, cv.TM_CCOEFF_NORMED)\n",
    "        loc = np.where(res >= threshold)\n",
    "\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            all_detected = np.append(all_detected,[pt[1],pt[1] + th])\n",
    "    all_detected = all_detected.reshape((-1,2)).astype(int)\n",
    "    modes = mode(all_detected, axis=0).mode\n",
    "\n",
    "    # guaranteed that mode only has 2 different values, so hard coding this in is okay\n",
    "    images = [img[:modes[0],:,:],img[modes[0]:modes[1],:,:],img[modes[1]:,:,:]]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function copied with continued lack of shame \n",
    "# removes the lines under course codes. Hard for pytesseract to\n",
    "# read underlined words\n",
    "def remove_underlines(img):\n",
    "    gray_dst = to_bin(img)\n",
    "    edges = cv.Canny(img, 50, 150, apertureSize = 3)\n",
    "    horizontal_kernel = cv.getStructuringElement(cv.MORPH_RECT, (15,1))\n",
    "\n",
    "    # Using morph open to get lines inside the drawing\n",
    "    opening = cv.morphologyEx(edges, cv.MORPH_OPEN, horizontal_kernel)\n",
    "    cnts = cv.findContours(opening, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    mask = np.uint8(gray_dst)\n",
    "    mask = np.zeros(gray_dst.shape, np.uint8)\n",
    "    for c in cnts:\n",
    "        cv.drawContours(mask, [c], -1, (255,255,255),2)\n",
    "\n",
    "    # Second inpaint\n",
    "    return cv.inpaint(img, mask, 3, cv.INPAINT_TELEA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "42ec198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from stack overflow, makes as much sense to me as Chinese (I do not speak Chinese)\n",
    "# takes away pointless lines and circles, for improved contour and detection\n",
    "def remove_lines_and_circles(img):\n",
    "    thresh = cv.threshold(img, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "    horizontal_kernel = cv.getStructuringElement(cv.MORPH_RECT, (25,1))\n",
    "    detected_lines = cv.morphologyEx(thresh, cv.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "    cnts = cv.findContours(detected_lines, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        cv.drawContours(img, [c], -1, (255,255,255), 2)\n",
    "    repair_kernel = cv.getStructuringElement(cv.MORPH_RECT, (1,6))\n",
    "    img = (255 - cv.morphologyEx(255 - img, cv.MORPH_CLOSE, repair_kernel, iterations=1))\n",
    "\n",
    "    blurred = cv.GaussianBlur(img, (5, 5), 0)\n",
    "    binary = cv.threshold(blurred, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "\n",
    "    contours = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "    for c in contours:\n",
    "        area = cv.contourArea(c)\n",
    "        if area < 1:  # skip noise\n",
    "            continue\n",
    "        perimeter = cv.arcLength(c, True)\n",
    "        if perimeter == 0:\n",
    "            continue\n",
    "        circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "        if 0.92 < circularity < 1.2:  # near-perfect circles\n",
    "            cv.drawContours(img, [c], -1, (255, 255, 255), -1)  # fill with white\n",
    "\n",
    "    return img\n",
    "\n",
    "# check how necessary this is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8219da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise\n",
    "def noise_removal(image):\n",
    "    import numpy as np\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv.dilate(image, kernel, iterations=2)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv.erode(image, kernel, iterations=2)\n",
    "    image = cv.morphologyEx(image, cv.MORPH_CLOSE, kernel)\n",
    "    image = cv.medianBlur(image, 3)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lines thicker and thinner\n",
    "\n",
    "# thicker\n",
    "def thick_line(img):\n",
    "    img = cv.bitwise_not(img)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img = cv.dilate(img, kernel, iterations=7)\n",
    "    img = cv.bitwise_not(img)\n",
    "    return img\n",
    "\n",
    "# thinner\n",
    "def thin_line(img):\n",
    "    img = cv.bitwise_not(img)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img = cv.erode(img, kernel, iterations=1)\n",
    "    img = cv.bitwise_not(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "be56fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurs images to improve contour detection \n",
    "# for splitting periods\n",
    "\n",
    "def blur_img(im):\n",
    "    return cv.GaussianBlur(im,(17,17),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3effda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurs the values further to form boxes for periods\n",
    "\n",
    "def blow_up(im, blur_values):\n",
    "    thresh = cv.threshold(im,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)[1]\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT,blur_values)\n",
    "\n",
    "    return cv.dilate(thresh,kernel,iterations=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates image based on contours\n",
    "\n",
    "def bounding_boxes(im, og_im, h_cap=40, w_cap=40):\n",
    "    cnts = cv.findContours(im, cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    cnts = sorted(cnts, key=lambda x: cv.boundingRect(x)[0])\n",
    "    roi = []\n",
    "    x_pos = []\n",
    "    img_cop = og_im.copy()\n",
    "    img_cop = remove_object(img_cop, annoying_book)\n",
    "    img_cop = remove_object(img_cop, annoying_wreath)\n",
    "    img_cop = remove_underlines(img_cop)\n",
    "    img_cop2 = img_cop.copy()\n",
    "    for c in cnts:\n",
    "        x, y, w,h = cv.boundingRect(c)\n",
    "        if h > h_cap and w > w_cap:\n",
    "            x_pos.append(x)\n",
    "            roi.append(img_cop[y:y+h,x:x+w])\n",
    "            cv.rectangle(img_cop2,(x,y),(x+w,y+h), (36,255,12), 2)\n",
    "    return img_cop2, roi, x_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "4e33ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a raw image and spits out relevant boxes\n",
    "# can be directly used to obtain periods from image\n",
    "\n",
    "def divide(im, dilated_bounds,h=40, w=40):\n",
    "    im_bin = to_bin(im)\n",
    "    fluff_removed = remove_lines_and_circles(im_bin)\n",
    "    blurred = blur_img(fluff_removed)\n",
    "    dilated = blow_up(blurred, dilated_bounds)\n",
    "    _, periods, x_pos = bounding_boxes(dilated, im,h,w)\n",
    "    return periods, x_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034a7cb",
   "metadata": {},
   "source": [
    "# Processing - Periods to courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d14f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase DPI to improve text detection\n",
    "\n",
    "def dpi_increase(image, scale_factor):\n",
    "    # Resize image by 2x or 3x to simulate higher DPI\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv.resize(image, (width * scale_factor, height * scale_factor), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    data = pyt.image_to_data(image, output_type=\"dict\")\n",
    "\n",
    "    heights = []\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['text'][i].isupper():\n",
    "            heights.append(data['height'][i])\n",
    "\n",
    "    if heights:\n",
    "        avg_cap_height = sum(heights) / len(heights)\n",
    "\n",
    "        # Scale image if too small\n",
    "        if avg_cap_height < 30:\n",
    "            scale = 30.0 / avg_cap_height\n",
    "            h, w = image.shape[:2]\n",
    "            image = cv.resize(image, (int(w * scale), int(h * scale)), interpolation=cv.INTER_CUBIC)\n",
    "    return image\n",
    "\n",
    "# img = dpi_increase(img, 4)\n",
    "\n",
    "# display(img)\n",
    "\n",
    "\n",
    "# for processed[1][1][2]:\n",
    "# does it correctly, but the proceeds to also give the ENTIRE thing\n",
    "# add in a safeguard so that if there are more than two codes present,\n",
    "# then it checks to see if there are any duplicates and then does stuff\n",
    "# sum like that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8afe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divides a period box to course boxes\n",
    "\n",
    "def divide_to_courses(img,dilated_bounds=(10,28)):\n",
    "    scale = 5\n",
    "    courses, x_pos = divide(img, dilated_bounds)\n",
    "    x_pos = [i*scale for i in x_pos]\n",
    "    hd = []\n",
    "    for course in courses:\n",
    "        course_hd = dpi_increase(course,scale)\n",
    "        course_bin = to_bin(course_hd)\n",
    "        hd.append(course_bin)\n",
    "\n",
    "    return hd, x_pos\n",
    "\n",
    "\n",
    "# Add in some \"did you mean\" safeguards: processed[3][2] returns\n",
    "# odern science... and ...complex nwnbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d65925",
   "metadata": {},
   "source": [
    "# Processing - Courses to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86affddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes text to form\n",
    "\n",
    "def text_processing(courses, x_pos, course_pos, course_df=pd.DataFrame(columns=[\"Code\",\"Name\", \"Period\"])):\n",
    "\n",
    "    for i, img in enumerate(courses):\n",
    "        text = pyt.image_to_data(img, output_type=\"data.frame\")\n",
    "        text = text.dropna(subset=[\"text\"])\n",
    "        if len(text) == 0:\n",
    "            continue\n",
    "        #below mask and operations remove all empty rows\n",
    "        mask = text[\"text\"].str.match(r\"^\\s+$|^\\s*Pass\\s*$\")\n",
    "        # mask = text[\"text\"].str.match(r\"^\\s+$\")\n",
    "        text = text[~mask]\n",
    "        text_final = text[(text.conf > 10)].reset_index(drop=True) \n",
    "        text_final[\"text\"] = text_final[\"text\"].str.replace(\"|\",\"I\", regex=False)\n",
    "        # play with the confidence value above. Too high and it risks cutting words out that are not fully in\n",
    "        # the picture, and too low and it might include weird symbols\n",
    "        #below mask finds all course codes\n",
    "        matches = text_final[\"text\"].str.match(r\"^[A-Z]{2,4}-?[A-Z0-9]{0,6}$\")\n",
    "        # skips if there is no course code in the image\n",
    "        # could be a good place to add in period finderz\n",
    "        if not matches.any():\n",
    "            continue # LATER MAKE THIS SO THAT ALL THE PICS WITH NO MATCHES ARE STORED,\n",
    "        # SO THAT MISTAKES CAN BE BETTER TAKEN CARE OF\n",
    "        # Also, SUO gets read as SUQ sometimes. I couldnt find any instances of Q\n",
    "        # in course codes so it might be fine to just replace all Qs\n",
    "        text_final[\"flag\"] = matches.cumsum()\n",
    "        course_word = text_final[~matches]\n",
    "        course_name = course_word.groupby(\"flag\")[\"text\"].apply(\" \".join).rename(\"Name\")\n",
    "        course_name = course_name.str.replace(r\"^\\s*\\d+\\s*\",\"\", regex=True)\n",
    "        course_code = text_final[matches][[\"text\", \"flag\", \"left\"]].rename(columns={\"text\": \"Code\", \"left\": \"X Position\"})\n",
    "        course_code[\"X Position\"] = course_code[\"X Position\"] + x_pos + course_pos[i]\n",
    "        course_code[\"Code\"] = course_code[\"Code\"].str.replace(\"Q\", \"O\",regex=False)\n",
    "        # this last line can be moved out, and instead just \n",
    "        # pd.merge(course_code, course_name, on=\"flag\")[[\"Code\", \"Name\"]] can be returned\n",
    "        course_df = pd.concat([course_df,pd.merge(course_code, course_name, on=\"flag\")[[\"Code\", \"Name\", \"X Position\"]]])\n",
    "\n",
    "    return course_df.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "8ccac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_period(course_df, period_img):\n",
    "    #process period text\n",
    "    period_img, x_pos = divide(period_img, (10,10),2,2)\n",
    "    x_pos = [i*5 for i in x_pos]\n",
    "    period_text = pd.DataFrame()\n",
    "    for i, img in enumerate(period_img):\n",
    "        img = dpi_increase(img,5)\n",
    "        img = to_bin(img)\n",
    "        img_text = pyt.image_to_data(img, output_type=\"data.frame\")\n",
    "        img_text[\"Position\"] = img_text[\"left\"] + x_pos[i]\n",
    "        if period_text.empty:\n",
    "            period_text = img_text\n",
    "        else:\n",
    "            period_text = pd.concat([period_text, img_text])\n",
    "    period_text = period_text[(period_text.conf > 10)]\n",
    "    period_text = period_text.dropna(subset=[\"text\"])\n",
    "    period_text[\"text\"] = period_text[\"text\"].str.replace(\"Swumer\",\"Summer\", regex=False)\n",
    "\n",
    "\n",
    "    # group each period\n",
    "    period_grouper = DBSCAN(eps=200, min_samples=1)\n",
    "    period_grouper.fit(np.array(period_text[\"Position\"]).reshape(-1,1)) \n",
    "    period_text[\"Labels\"] = period_grouper.labels_\n",
    "    periods = period_text.groupby(\"Labels\")[\"text\"].apply(\" \".join).reset_index().rename(columns={\"text\": \"Period\"})\n",
    "\n",
    "    # group course to period\n",
    "    # add in a safeguard to check what happens if len(labels)\n",
    "    # of courses and period dont match\n",
    "    course_eps = min(x_pos)/2\n",
    "    course_grouper = DBSCAN(eps=course_eps, min_samples=1)\n",
    "    course_grouper.fit(np.array(course_df[\"X Position\"]).reshape(-1,1))\n",
    "    course_df[\"Labels\"] = course_grouper.labels_\n",
    "    course_df = pd.merge(course_df,periods, on=\"Labels\")[[\"Code\",\"Name\",\"Period\"]]\n",
    "\n",
    "    return course_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d5383326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full function\n",
    "    #make all these values - eps=10, scale=5, (35,7) work with all \n",
    "    #image scales\n",
    "\n",
    "def img_to_database(im):\n",
    "    courses_df = pd.DataFrame(columns=[\"Code\",\"Name\", \"X Position\"])\n",
    "    imgs = split_image(im, cv.imread(\"Testing/Period.png\"))\n",
    "    periods,x_pos = divide(imgs[2],(1,100))\n",
    "    # even if no dpi increase on first one, we still need to scale\n",
    "    # up to account for the scaling of the in divide_to_courses\n",
    "    x_pos = [i*5 for i in x_pos]\n",
    "    for i, period in enumerate(periods):\n",
    "        courses, course_pos = divide_to_courses(period)\n",
    "        courses_df = text_processing(courses, x_pos[i], course_pos, courses_df)\n",
    "\n",
    "    courses_df = locate_period(courses_df, imgs[1])\n",
    "    return courses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a67991",
   "metadata": {},
   "source": [
    "Where are the main problems when it comes to character recognition?\n",
    "\n",
    "1. Try and change to EasyOCR, it might be better\n",
    "2. T -> 1\n",
    "3. O -> Q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
